File name: Navigating_Critical_Thinking_in_the_Digital_Era_An.pdf


	The International Journal of Linguistics, Literature, and Translation explores the intersection of critical thinking and artificial intelligence in the digital era. The article delves into how AI tools can either enhance or hinder students' critical thinking skills. It raises questions about the impact of AI on education, ethical considerations, and the challenges faced by educators and students in navigating the digital landscape. The importance of fostering critical thinking skills within technology-rich environments is emphasized, along with the need for educators to empower students to question and critically analyze AI-generated information. The article also discusses the role of AI in classroom tests, the funding of AI in education, and the potential for AI to enhance analytical skills and promote lifelong learning. Overall, the article advocates for a balanced integration of AI as a complementary tool to empower students to navigate the complexities of the digital age with critical thinking and ethical responsibility.



	Regarding the usage of generative AI technologies, both students (mean = 2.28, SD = 1.18) and teachers (mean = 2.02, SD = 1.1) reported relatively low experience, suggesting that there is significant room for growth in adoption. Both groups demonstrated a belief in the positive impact of integrating AI technologies into higher education (students: mean = 4, SD = 0.891; teachers: mean = 3.87, SD = 1.32). This optimism was also reflected in the strong agreement that institutions should have plans in place associated with AI technologies (students: mean = 4.5, SD = 0.854; teachers: mean = 4.54, SD = 0.874).

Both students and teachers were open to integrating AI technologies into their future teaching and learning practices (students: mean = 3.93, SD = 1.09; teachers: mean = 3.92, SD = 1.31). However, there were concerns among both groups about other students using AI technologies to get ahead in their assignments (students: mean = 3.67, SD = 1.22; teachers: mean = 3.93, SD = 1.12). Interestingly, both students and teachers did not strongly agree that AI technologies would replace teachers in the future (students: mean = 2.14, SD = 1.12; teachers: mean = 2.26, SD = 1.34).

The respondents acknowledged the importance of learning to use generative AI technologies well for their careers (students: mean = 4.07, SD = 0.998; teachers: mean = 4.1, SD = 1.08). However, both groups expressed doubt about teachers’ ability to accurately identify a student’s usage of generative AI technologies for completing assignments (students: mean = 3.02, SD = 1.56; teachers: mean = 2.72, SD = 1.62).

The responses to the remaining questions suggest that students and teachers recognize potential benefits and drawbacks of AI technologies, including providing guidance and personalized feedback, improving digital competence and academic performance, and offering anonymity in student support services. However, there were concerns about over-reliance on AI technologies, limited social interaction, and the potential hindrance to the development of generic skills.

These findings highlight the need for a comprehensive AI policy in higher education that addresses the potential risks and opportunities associated with generative AI technologies. Based on these findings, some implications and suggestions for university teaching and learning AI policy include:

1.
Training: Providing training for both students and teachers on effectively using and integrating generative AI technologies into teaching and learning practices.

2.
Ethical Use and Risk Management: Developing policies and guidelines for ethical use and risk management associated with generative AI technologies.

3.
Incorporating AI without replacing human: Incorporating AI technologies as supplementary tools to assist teachers and students, rather than as replacements for human interaction.

4.
Continuously Enhancing Holistic Competencies: Encouraging the use of AI technologies to enhance specific skills, such as digital competence and time management, while ensuring that students continue to develop vital transferable skills.

5.
Fostering a transparent AI environment: Fostering a transparent environment where students and teachers can openly discuss the benefits and concerns associated with using AI technologies in higher education.

6.
Data Privacy and security: Ensuring data privacy and security while using AI technologies.

Overall, the survey results indicate an openness to adopting generative AI technologies in higher education and a recognition of the potential advantages and challenges. Addressing these issues through informed policy and institutional support will be crucial for maximizing the benefits of AI technologies in university teaching and learning.

Findings from the qualitative data
The qualitative data collected from students, teachers, and staff yielded valuable and rich suggestions and comments. There are 10 main themes and 25 subthemes that emerged from the qualitative data as presented in Table 3. From the data, we identified ten key areas (i.e., the main themes) that are directly relevant to the planning of an AI policy for teaching and learning in universities. These areas align well with the quantitative data and are as follows:

(1)
Understanding, identifying and preventing academic misconduct and ethical dilemmas

Triangulating quantitative and qualitative data
The quantitative findings support the key areas found in the qualitative data for AI integration in education. The quantitative data reveals that both students and teachers share concerns about the potential misuse of AI technologies, such as ChatGPT, in assignments (students: mean 3.67, teachers: mean 3.93). This emphasizes the need for guidelines and strategies to prevent academic misconduct. Furthermore, there is significant agreement among students and teachers on the necessity for higher education institutions to implement a plan for managing the potential risks associated with using generative AI technologies (students: mean 4.5, teachers: mean 4.54), highlighting the importance of addressing data privacy, transparency, accountability, and security. The overall positive perception of AI technologies integration within education implies that proper policies should be in place to ensure responsible AI incorporation in higher education.

The concern that some students might use generative AI technologies to gain an advantage in their assignments (students: mean 3.67, teachers: mean 3.93) underscores the importance of ensuring equal access to AI technologies for all students. Moreover, the consensus that students must become proficient in using generative AI technologies for their careers (students: mean 4.07, teachers: mean 4.1) highlights the need for AI literacy and training for all stakeholders in the educational process, preparing students for the AI-driven workplace.

Interestingly, teachers and students are unsure if teachers can accurately identify a student’s use of generative AI technologies to partially complete an assignment (students: mean 3.02, teachers: mean 2.72), yet they also believe that AI technologies can provide unique insights and perspectives and personalized feedback. This suggests that rethinking assessment methods may be necessary.

Data indicating that neither students nor teachers believe AI technologies will replace teachers in the future (students: mean 2.14, teachers: mean 2.26) supports the need for a balanced approach to AI adoption, utilizing AI technologies as complementary tools rather than substitutes for traditional teaching methods. Finally, concerns that generative AI technologies could hinder students’ development of generic or transferable skills, such as teamwork, problem-solving, and leadership (students: mean 3.3, teachers: mean 3.74), emphasize the importance of focusing on students’ holistic competencies and generic skills in preparation for the AI-driven workplace.

Key areas versus UNESCO’s recommendations on AI education policy
The original plan for the study was to use UNESCO’s recommendations as a basis for developing AI education policy framework for university teaching and learning through inputs from various stakeholders to identify any gaps in the framework and modified accordingly. Although the recommendations from UNESCO can provide a high-level guideline for this study, it was clear that there are several key differences between UNESCO recommendations and the ten key areas that were identified for integrating AI in university teaching and learning.

As the UNESCO’s AI and Education: Guidance for Policy-Makers was written before the availability of GPT 3.5 and 4, the recommendations would not have fully addressed the current opportunities and threats of the advances in the GPT technologies for education.

Moreover, the UNESCO recommendations are intended for education in general and do not specifically cater to the needs of university teaching and learning. The UNESCO recommendations are high-level and general aimed at helping policy-makers better understand the possibilities and implications of AI for teaching and learning to help achieve Sustainable Development Goal 4: Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all (UNESCO, 2021a), while the ten key areas are more specific, practical, and tailored to university teaching and learning. Furthermore, most of the existing AI education policies tend to emphasize the instrumental role of AI for workforce development (Schiff, 2022), but the key areas based on the findings of this study also address the transformative potential and ethical considerations relating to AI use in higher education in addition to its instrumental purposes.

The ten key areas were developed based on direct input from stakeholders who have vested interests in university teaching and learning, which makes them more relevant and grounded in practice. For example, UNESCO’s recommendation to develop a master plan for using AI for education management, teaching, learning, and assessment emphasizes the need for a comprehensive and strategic approach to integrating AI in various aspects of education. This includes not only teaching and learning but also the broader aspects of education management, such as administration, resource allocation, and policy development. The focus here is on creating an overarching framework that guides the implementation of AI in education as a whole. On the other hand, the key area derived from the qualitative findings of rethinking assessments and examinations delves deeper into a specific aspect of education: the evaluation of students’ learning. This area acknowledges that the integration of generative AI in education necessitates a re-evaluation of traditional assessment methods. The focus here is on designing assessments that allow AI technologies to enhance learning outcomes while maintaining academic integrity. This involves developing new assessment strategies that focus on students’ understanding, critical thinking, and analysis rather than just their ability to collect information. In short, UNESCO’s recommendations highlight the “what”, whereas the ten key areas of this study detail the “how” of AI education policy.

In essence, the difference between these two areas lies in their scope and focus. UNESCO’s recommendation is broader, encompassing various aspects of education and advocating for a comprehensive master plan. Its primary target is policymakers. In contrast, the key area on rethinking assessments and examinations is more specific and user centred, catering for various higher education stakeholders including students and teachers as well as addressing the challenges and opportunities associated with AI integration in university teaching and learning.